{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5908a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06bb1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from model import deanGMVAE  # Adjust this import statement as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6d9c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deanGMVAE(\n",
       "  (encoder): DeanEncoderGMM(\n",
       "    (conv1): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (conv4): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (fc_mu): Linear(in_features=4096, out_features=72, bias=True)\n",
       "    (fc_logvar): Linear(in_features=4096, out_features=72, bias=True)\n",
       "    (fc_pi): Linear(in_features=4096, out_features=8, bias=True)\n",
       "  )\n",
       "  (decoder): DeanDecGMM(\n",
       "    (fc): Linear(in_features=9, out_features=4096, bias=True)\n",
       "    (deconv1): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (deconv2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (deconv3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (deconv4): ConvTranspose2d(32, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./weights/C8_Disentanglement_17_6_0.792_0.3_0.00048114888561434383_adam_9_626.7850927065497_606.3880588061189_14.004697956450999_6.392335702295172_8_0.3387780262488029.pth\"  # Update this path\n",
    "model_trained = deanGMVAE(z_dim=9, beta=0.00048114888561434383, dropout=0.3, K=8)\n",
    "model_trained.load_state_dict(torch.load(path))\n",
    "model_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01bf00f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_from_latent(model, dim_to_explore, val, latent_size=9):\n",
    "    with torch.no_grad():\n",
    "        # Generate a baseline latent vector with the specified dimension varied\n",
    "        z = torch.zeros((1, latent_size))\n",
    "        z[0, dim_to_explore] = val\n",
    "        \n",
    "        # Use the decoder to generate an image from the latent vector\n",
    "        img = model.decoder(z).squeeze(0)  # Assuming the output is (C, H, W)\n",
    "        \n",
    "        # Process the image to visualize the 4 channels as specified:\n",
    "        # First 3 channels are directly mapped; the 4th channel adds to all RGB.\n",
    "        rgb_image = np.zeros((img.shape[1], img.shape[2], 3), dtype=np.float32)  # Prepare an empty RGB image\n",
    "        \n",
    "        # Map the first 3 channels to RGB and add the 4th channel to each RGB channel\n",
    "        rgb_image[:, :, 0] = img[1, :, :] + img[3, :, :]  # R + 4th\n",
    "        rgb_image[:, :, 1] = img[2, :, :] + img[3, :, :]  # G + 4th\n",
    "        rgb_image[:, :, 2] = img[0, :, :] + img[3, :, :]  # B + 4th\n",
    "        \n",
    "        # Normalize the image to be in the [0, 1] range\n",
    "        rgb_image = np.clip(rgb_image / rgb_image.max(), 0, 1)\n",
    "        \n",
    "        return rgb_image  # Return the numpy array of the processed image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd7212f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d458ebeeb648bea5c4e369c4092e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Dim 0', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7a81cf38154eaaaa372f10b9772407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Dim 1', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5495b213ae64bfaae5c5cd8cf8508b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Dim 2', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195b4b93c18c40c3b8a2a1fc0fac2d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Dim 3', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f37d5d4d3aa46369e51a9c00fb183ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Dim 4', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e791e883af584cf188dfcf544cf9a6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Dim 5', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c51373c03d45cca6ad700eca4fd931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Dim 6', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1052be6f6204d40afc0f84ffb23f79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Dim 7', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e87cd1df11e468e8117a77fe1c6239b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Dim 8', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39acd728aab42448981574d0c97b894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_dim = 9  # or however many dimensions your model has\n",
    "sliders = [widgets.FloatSlider(value=0.0, min=-1, max=1, step=0.1, description=f'Dim {i}') for i in range(latent_dim)]\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_value_change(change, dim):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        # Call your modified function to generate and display the image\n",
    "        val = sliders[dim].value\n",
    "        img = generate_image_from_latent(model_trained, dim, val)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "for i, slider in enumerate(sliders):\n",
    "    slider.observe(lambda change, dim=i: on_value_change(change, dim), names='value')\n",
    "    \n",
    "display(*sliders, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa635d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
